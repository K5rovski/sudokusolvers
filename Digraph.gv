digraph {
	graph [size="46.8,46.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1333791775376 [label="
 ()" fillcolor=darkolivegreen1]
	1333792288096 [label=MeanBackward0]
	1333792288336 -> 1333792288096
	1333792288336 [label=MkldnnConvolutionBackward0]
	1333792287712 -> 1333792288336
	1333792287712 [label=ReluBackward0]
	1333792287568 -> 1333792287712
	1333792287568 [label=NativeBatchNormBackward0]
	1333792287616 -> 1333792287568
	1333792287616 [label=MkldnnConvolutionBackward0]
	1333792287136 -> 1333792287616
	1333792287136 [label=ReluBackward0]
	1333792286800 -> 1333792287136
	1333792286800 [label=NativeBatchNormBackward0]
	1333792286944 -> 1333792286800
	1333792286944 [label=MkldnnConvolutionBackward0]
	1333792286608 -> 1333792286944
	1333792286608 [label=CatBackward0]
	1333792285888 -> 1333792286608
	1333792285888 [label=ReluBackward0]
	1333792286272 -> 1333792285888
	1333792286272 [label=NativeBatchNormBackward0]
	1333792286368 -> 1333792286272
	1333792286368 [label=MkldnnConvolutionBackward0]
	1333792287760 -> 1333792286368
	1333792287760 [label=ReluBackward0]
	1333792286176 -> 1333792287760
	1333792286176 [label=NativeBatchNormBackward0]
	1333792285984 -> 1333792286176
	1333792285984 [label=MkldnnConvolutionBackward0]
	1333792285696 -> 1333792285984
	1333690724736 [label="downs.0.conv.0.weight
 (64, 10, 3, 3)" fillcolor=lightblue]
	1333690724736 -> 1333792285696
	1333792285696 [label=AccumulateGrad]
	1333792286224 -> 1333792286176
	1333690725696 [label="downs.0.conv.1.weight
 (64)" fillcolor=lightblue]
	1333690725696 -> 1333792286224
	1333792286224 [label=AccumulateGrad]
	1333792286080 -> 1333792286176
	1333690725776 [label="downs.0.conv.1.bias
 (64)" fillcolor=lightblue]
	1333690725776 -> 1333792286080
	1333792286080 [label=AccumulateGrad]
	1333792286032 -> 1333792286368
	1333690727056 [label="downs.0.conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1333690727056 -> 1333792286032
	1333792286032 [label=AccumulateGrad]
	1333792286464 -> 1333792286272
	1333690727136 [label="downs.0.conv.4.weight
 (64)" fillcolor=lightblue]
	1333690727136 -> 1333792286464
	1333792286464 [label=AccumulateGrad]
	1333792286512 -> 1333792286272
	1333690727216 [label="downs.0.conv.4.bias
 (64)" fillcolor=lightblue]
	1333690727216 -> 1333792286512
	1333792286512 [label=AccumulateGrad]
	1333792286656 -> 1333792286608
	1333792286656 [label=UpsampleBilinear2DBackward1]
	1333792286320 -> 1333792286656
	1333792286320 [label=SlowConvTranspose2DBackward0]
	1333792285792 -> 1333792286320
	1333792285792 [label=ReluBackward0]
	1333792285936 -> 1333792285792
	1333792285936 [label=NativeBatchNormBackward0]
	1333792285600 -> 1333792285936
	1333792285600 [label=MkldnnConvolutionBackward0]
	1333792285264 -> 1333792285600
	1333792285264 [label=ReluBackward0]
	1333792285408 -> 1333792285264
	1333792285408 [label=NativeBatchNormBackward0]
	1333792284976 -> 1333792285408
	1333792284976 [label=MkldnnConvolutionBackward0]
	1333792284928 -> 1333792284976
	1333792284928 [label=CatBackward0]
	1333792284784 -> 1333792284928
	1333792284784 [label=ReluBackward0]
	1335588355136 -> 1333792284784
	1335588355136 [label=NativeBatchNormBackward0]
	1335588354992 -> 1335588355136
	1335588354992 [label=MkldnnConvolutionBackward0]
	1333791723328 -> 1335588354992
	1333791723328 [label=ReluBackward0]
	1333791723184 -> 1333791723328
	1333791723184 [label=NativeBatchNormBackward0]
	1333791723040 -> 1333791723184
	1333791723040 [label=MkldnnConvolutionBackward0]
	1335618119328 -> 1333791723040
	1335618119328 [label=MaxPool2DWithIndicesBackward0]
	1333792285888 -> 1335618119328
	1333690566688 -> 1333791723040
	1333690727936 [label="downs.1.conv.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1333690727936 -> 1333690566688
	1333690566688 [label=AccumulateGrad]
	1333791723136 -> 1333791723184
	1333690728016 [label="downs.1.conv.1.weight
 (128)" fillcolor=lightblue]
	1333690728016 -> 1333791723136
	1333791723136 [label=AccumulateGrad]
	1333791723280 -> 1333791723184
	1333690728096 [label="downs.1.conv.1.bias
 (128)" fillcolor=lightblue]
	1333690728096 -> 1333791723280
	1333791723280 [label=AccumulateGrad]
	1333791723376 -> 1335588354992
	1333690785936 [label="downs.1.conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1333690785936 -> 1333791723376
	1333791723376 [label=AccumulateGrad]
	1335588352976 -> 1335588355136
	1333690786016 [label="downs.1.conv.4.weight
 (128)" fillcolor=lightblue]
	1333690786016 -> 1335588352976
	1335588352976 [label=AccumulateGrad]
	1333791723088 -> 1335588355136
	1333690786096 [label="downs.1.conv.4.bias
 (128)" fillcolor=lightblue]
	1333690786096 -> 1333791723088
	1333791723088 [label=AccumulateGrad]
	1333792284736 -> 1333792284928
	1333792284736 [label=SlowConvTranspose2DBackward0]
	1335588355040 -> 1333792284736
	1335588355040 [label=ReluBackward0]
	1333791723232 -> 1335588355040
	1333791723232 [label=NativeBatchNormBackward0]
	1333791854848 -> 1333791723232
	1333791854848 [label=MkldnnConvolutionBackward0]
	1333791855088 -> 1333791854848
	1333791855088 [label=ReluBackward0]
	1333791854896 -> 1333791855088
	1333791854896 [label=NativeBatchNormBackward0]
	1333791854752 -> 1333791854896
	1333791854752 [label=MkldnnConvolutionBackward0]
	1333791855664 -> 1333791854752
	1333791855664 [label=CatBackward0]
	1333791854656 -> 1333791855664
	1333791854656 [label=ReluBackward0]
	1333791855568 -> 1333791854656
	1333791855568 [label=NativeBatchNormBackward0]
	1333791855376 -> 1333791855568
	1333791855376 [label=MkldnnConvolutionBackward0]
	1333791855808 -> 1333791855376
	1333791855808 [label=ReluBackward0]
	1333791855328 -> 1333791855808
	1333791855328 [label=NativeBatchNormBackward0]
	1333791855904 -> 1333791855328
	1333791855904 [label=MkldnnConvolutionBackward0]
	1333791855232 -> 1333791855904
	1333791855232 [label=MaxPool2DWithIndicesBackward0]
	1333792284784 -> 1333791855232
	1333791855856 -> 1333791855904
	1333690786496 [label="downs.2.conv.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1333690786496 -> 1333791855856
	1333791855856 [label=AccumulateGrad]
	1333791856096 -> 1333791855328
	1333690786576 [label="downs.2.conv.1.weight
 (256)" fillcolor=lightblue]
	1333690786576 -> 1333791856096
	1333791856096 [label=AccumulateGrad]
	1333791858496 -> 1333791855328
	1333690786656 [label="downs.2.conv.1.bias
 (256)" fillcolor=lightblue]
	1333690786656 -> 1333791858496
	1333791858496 [label=AccumulateGrad]
	1333791856000 -> 1333791855376
	1333690787056 [label="downs.2.conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1333690787056 -> 1333791856000
	1333791856000 [label=AccumulateGrad]
	1333791855280 -> 1333791855568
	1333690787136 [label="downs.2.conv.4.weight
 (256)" fillcolor=lightblue]
	1333690787136 -> 1333791855280
	1333791855280 [label=AccumulateGrad]
	1333791856720 -> 1333791855568
	1333690787216 [label="downs.2.conv.4.bias
 (256)" fillcolor=lightblue]
	1333690787216 -> 1333791856720
	1333791856720 [label=AccumulateGrad]
	1333791855712 -> 1333791855664
	1333791855712 [label=SlowConvTranspose2DBackward0]
	1333791855760 -> 1333791855712
	1333791855760 [label=ReluBackward0]
	1333791858640 -> 1333791855760
	1333791858640 [label=NativeBatchNormBackward0]
	1333791858400 -> 1333791858640
	1333791858400 [label=MkldnnConvolutionBackward0]
	1333791858112 -> 1333791858400
	1333791858112 [label=ReluBackward0]
	1333791857776 -> 1333791858112
	1333791857776 [label=NativeBatchNormBackward0]
	1333791857680 -> 1333791857776
	1333791857680 [label=MkldnnConvolutionBackward0]
	1333791857296 -> 1333791857680
	1333791857296 [label=MaxPool2DWithIndicesBackward0]
	1333791854656 -> 1333791857296
	1333791857392 -> 1333791857680
	1333690874032 [label="bottleneck.conv.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1333690874032 -> 1333791857392
	1333791857392 [label=AccumulateGrad]
	1333791857728 -> 1333791857776
	1333690874112 [label="bottleneck.conv.1.weight
 (512)" fillcolor=lightblue]
	1333690874112 -> 1333791857728
	1333791857728 [label=AccumulateGrad]
	1333791858016 -> 1333791857776
	1333690874192 [label="bottleneck.conv.1.bias
 (512)" fillcolor=lightblue]
	1333690874192 -> 1333791858016
	1333791858016 [label=AccumulateGrad]
	1333791858208 -> 1333791858400
	1333690874592 [label="bottleneck.conv.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1333690874592 -> 1333791858208
	1333791858208 [label=AccumulateGrad]
	1333791858448 -> 1333791858640
	1333690874672 [label="bottleneck.conv.4.weight
 (512)" fillcolor=lightblue]
	1333690874672 -> 1333791858448
	1333791858448 [label=AccumulateGrad]
	1333791856048 -> 1333791858640
	1333690874752 [label="bottleneck.conv.4.bias
 (512)" fillcolor=lightblue]
	1333690874752 -> 1333791856048
	1333791856048 [label=AccumulateGrad]
	1333791855472 -> 1333791855712
	1333690787776 [label="ups.0.weight
 (512, 256, 2, 2)" fillcolor=lightblue]
	1333690787776 -> 1333791855472
	1333791855472 [label=AccumulateGrad]
	1333791856144 -> 1333791855712
	1333690787856 [label="ups.0.bias
 (256)" fillcolor=lightblue]
	1333690787856 -> 1333791856144
	1333791856144 [label=AccumulateGrad]
	1333791854992 -> 1333791854752
	1333690788176 [label="ups.1.conv.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	1333690788176 -> 1333791854992
	1333791854992 [label=AccumulateGrad]
	1333791854800 -> 1333791854896
	1333690788256 [label="ups.1.conv.1.weight
 (256)" fillcolor=lightblue]
	1333690788256 -> 1333791854800
	1333791854800 [label=AccumulateGrad]
	1333791858064 -> 1333791854896
	1333690788336 [label="ups.1.conv.1.bias
 (256)" fillcolor=lightblue]
	1333690788336 -> 1333791858064
	1333791858064 [label=AccumulateGrad]
	1333791856288 -> 1333791854848
	1333690788736 [label="ups.1.conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1333690788736 -> 1333791856288
	1333791856288 [label=AccumulateGrad]
	1333791857056 -> 1333791723232
	1333690788816 [label="ups.1.conv.4.weight
 (256)" fillcolor=lightblue]
	1333690788816 -> 1333791857056
	1333791857056 [label=AccumulateGrad]
	1333791855184 -> 1333791723232
	1333690788896 [label="ups.1.conv.4.bias
 (256)" fillcolor=lightblue]
	1333690788896 -> 1333791855184
	1333791855184 [label=AccumulateGrad]
	1333791723424 -> 1333792284736
	1333690789296 [label="ups.2.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	1333690789296 -> 1333791723424
	1333791723424 [label=AccumulateGrad]
	1333791723472 -> 1333792284736
	1333690789376 [label="ups.2.bias
 (128)" fillcolor=lightblue]
	1333690789376 -> 1333791723472
	1333791723472 [label=AccumulateGrad]
	1333792284880 -> 1333792284976
	1333690789536 [label="ups.3.conv.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	1333690789536 -> 1333792284880
	1333792284880 [label=AccumulateGrad]
	1333792285168 -> 1333792285408
	1333690789616 [label="ups.3.conv.1.weight
 (128)" fillcolor=lightblue]
	1333690789616 -> 1333792285168
	1333792285168 [label=AccumulateGrad]
	1333792285312 -> 1333792285408
	1333690789696 [label="ups.3.conv.1.bias
 (128)" fillcolor=lightblue]
	1333690789696 -> 1333792285312
	1333792285312 [label=AccumulateGrad]
	1333792285216 -> 1333792285600
	1333690872112 [label="ups.3.conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1333690872112 -> 1333792285216
	1333792285216 [label=AccumulateGrad]
	1333792285648 -> 1333792285936
	1333690872192 [label="ups.3.conv.4.weight
 (128)" fillcolor=lightblue]
	1333690872192 -> 1333792285648
	1333792285648 [label=AccumulateGrad]
	1333792285456 -> 1333792285936
	1333690872272 [label="ups.3.conv.4.bias
 (128)" fillcolor=lightblue]
	1333690872272 -> 1333792285456
	1333792285456 [label=AccumulateGrad]
	1333792285840 -> 1333792286320
	1333690872672 [label="ups.4.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	1333690872672 -> 1333792285840
	1333792285840 [label=AccumulateGrad]
	1333792286560 -> 1333792286320
	1333690872752 [label="ups.4.bias
 (64)" fillcolor=lightblue]
	1333690872752 -> 1333792286560
	1333792286560 [label=AccumulateGrad]
	1333792286752 -> 1333792286944
	1333690872912 [label="ups.5.conv.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	1333690872912 -> 1333792286752
	1333792286752 [label=AccumulateGrad]
	1333792286848 -> 1333792286800
	1333690872992 [label="ups.5.conv.1.weight
 (64)" fillcolor=lightblue]
	1333690872992 -> 1333792286848
	1333792286848 [label=AccumulateGrad]
	1333792287184 -> 1333792286800
	1333690873072 [label="ups.5.conv.1.bias
 (64)" fillcolor=lightblue]
	1333690873072 -> 1333792287184
	1333792287184 [label=AccumulateGrad]
	1333792287232 -> 1333792287616
	1333690873472 [label="ups.5.conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1333690873472 -> 1333792287232
	1333792287232 [label=AccumulateGrad]
	1333792287376 -> 1333792287568
	1333690873552 [label="ups.5.conv.4.weight
 (64)" fillcolor=lightblue]
	1333690873552 -> 1333792287376
	1333792287376 [label=AccumulateGrad]
	1333792287280 -> 1333792287568
	1333690873632 [label="ups.5.conv.4.bias
 (64)" fillcolor=lightblue]
	1333690873632 -> 1333792287280
	1333792287280 [label=AccumulateGrad]
	1333792287472 -> 1333792288336
	1333690875152 [label="final_conv.weight
 (9, 64, 1, 1)" fillcolor=lightblue]
	1333690875152 -> 1333792287472
	1333792287472 [label=AccumulateGrad]
	1333792287952 -> 1333792288336
	1333690875232 [label="final_conv.bias
 (9)" fillcolor=lightblue]
	1333690875232 -> 1333792287952
	1333792287952 [label=AccumulateGrad]
	1333792288096 -> 1333791775376
}
