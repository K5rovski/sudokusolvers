digraph {
	graph [size="46.8,46.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1333791775376 [label="
 ()" fillcolor=darkolivegreen1]
	1333791830368 [label=MeanBackward0]
	1333791832384 -> 1333791830368
	1333791832384 [label=MkldnnConvolutionBackward0]
	1333791833920 -> 1333791832384
	1333791833920 [label=ReluBackward0]
	1333791833680 -> 1333791833920
	1333791833680 [label=NativeBatchNormBackward0]
	1333791833776 -> 1333791833680
	1333791833776 [label=MkldnnConvolutionBackward0]
	1333791833344 -> 1333791833776
	1333791833344 [label=ReluBackward0]
	1333791830080 -> 1333791833344
	1333791830080 [label=NativeBatchNormBackward0]
	1333791832048 -> 1333791830080
	1333791832048 [label=MkldnnConvolutionBackward0]
	1333791830224 -> 1333791832048
	1333791830224 [label=CatBackward0]
	1333791832816 -> 1333791830224
	1333791832816 [label=ReluBackward0]
	1333791831328 -> 1333791832816
	1333791831328 [label=NativeBatchNormBackward0]
	1333791831136 -> 1333791831328
	1333791831136 [label=MkldnnConvolutionBackward0]
	1333791832288 -> 1333791831136
	1333791832288 [label=ReluBackward0]
	1333791830944 -> 1333791832288
	1333791830944 [label=NativeBatchNormBackward0]
	1333791831232 -> 1333791830944
	1333791831232 [label=MkldnnConvolutionBackward0]
	1333791830992 -> 1333791831232
	1333690724736 [label="downs.0.conv.0.weight
 (64, 10, 3, 3)" fillcolor=lightblue]
	1333690724736 -> 1333791830992
	1333791830992 [label=AccumulateGrad]
	1333791831280 -> 1333791830944
	1333690725696 [label="downs.0.conv.1.weight
 (64)" fillcolor=lightblue]
	1333690725696 -> 1333791831280
	1333791831280 [label=AccumulateGrad]
	1333791831040 -> 1333791830944
	1333690725776 [label="downs.0.conv.1.bias
 (64)" fillcolor=lightblue]
	1333690725776 -> 1333791831040
	1333791831040 [label=AccumulateGrad]
	1333791832240 -> 1333791831136
	1333690727056 [label="downs.0.conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1333690727056 -> 1333791832240
	1333791832240 [label=AccumulateGrad]
	1333791831376 -> 1333791831328
	1333690727136 [label="downs.0.conv.4.weight
 (64)" fillcolor=lightblue]
	1333690727136 -> 1333791831376
	1333791831376 [label=AccumulateGrad]
	1333791833296 -> 1333791831328
	1333690727216 [label="downs.0.conv.4.bias
 (64)" fillcolor=lightblue]
	1333690727216 -> 1333791833296
	1333791833296 [label=AccumulateGrad]
	1333791831424 -> 1333791830224
	1333791831424 [label=UpsampleBilinear2DBackward1]
	1333791832192 -> 1333791831424
	1333791832192 [label=SlowConvTranspose2DBackward0]
	1333791831184 -> 1333791832192
	1333791831184 [label=ReluBackward0]
	1333791830656 -> 1333791831184
	1333791830656 [label=NativeBatchNormBackward0]
	1333791834016 -> 1333791830656
	1333791834016 [label=MkldnnConvolutionBackward0]
	1333791832624 -> 1333791834016
	1333791832624 [label=ReluBackward0]
	1333791832096 -> 1333791832624
	1333791832096 [label=NativeBatchNormBackward0]
	1333791831904 -> 1333791832096
	1333791831904 [label=MkldnnConvolutionBackward0]
	1333791831088 -> 1333791831904
	1333791831088 [label=CatBackward0]
	1333791830464 -> 1333791831088
	1333791830464 [label=ReluBackward0]
	1333791830320 -> 1333791830464
	1333791830320 [label=NativeBatchNormBackward0]
	1333791723376 -> 1333791830320
	1333791723376 [label=MkldnnConvolutionBackward0]
	1333791723184 -> 1333791723376
	1333791723184 [label=ReluBackward0]
	1333791723040 -> 1333791723184
	1333791723040 [label=NativeBatchNormBackward0]
	1333791722896 -> 1333791723040
	1333791722896 [label=MkldnnConvolutionBackward0]
	1333690855184 -> 1333791722896
	1333690855184 [label=MaxPool2DWithIndicesBackward0]
	1333791832816 -> 1333690855184
	1333690855232 -> 1333791722896
	1333690727936 [label="downs.1.conv.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1333690727936 -> 1333690855232
	1333690855232 [label=AccumulateGrad]
	1333791722944 -> 1333791723040
	1333690728016 [label="downs.1.conv.1.weight
 (128)" fillcolor=lightblue]
	1333690728016 -> 1333791722944
	1333791722944 [label=AccumulateGrad]
	1333791723136 -> 1333791723040
	1333690728096 [label="downs.1.conv.1.bias
 (128)" fillcolor=lightblue]
	1333690728096 -> 1333791723136
	1333791723136 [label=AccumulateGrad]
	1333791723232 -> 1333791723376
	1333690785936 [label="downs.1.conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1333690785936 -> 1333791723232
	1333791723232 [label=AccumulateGrad]
	1333791723424 -> 1333791830320
	1333690786016 [label="downs.1.conv.4.weight
 (128)" fillcolor=lightblue]
	1333690786016 -> 1333791723424
	1333791723424 [label=AccumulateGrad]
	1333791723472 -> 1333791830320
	1333690786096 [label="downs.1.conv.4.bias
 (128)" fillcolor=lightblue]
	1333690786096 -> 1333791723472
	1333791723472 [label=AccumulateGrad]
	1333791830608 -> 1333791831088
	1333791830608 [label=SlowConvTranspose2DBackward0]
	1333791830512 -> 1333791830608
	1333791830512 [label=ReluBackward0]
	1333690855088 -> 1333791830512
	1333690855088 [label=NativeBatchNormBackward0]
	1333690854704 -> 1333690855088
	1333690854704 [label=MkldnnConvolutionBackward0]
	1333690566688 -> 1333690854704
	1333690566688 [label=ReluBackward0]
	1335618119328 -> 1333690566688
	1335618119328 [label=NativeBatchNormBackward0]
	1333791855424 -> 1335618119328
	1333791855424 [label=MkldnnConvolutionBackward0]
	1333791855520 -> 1333791855424
	1333791855520 [label=CatBackward0]
	1333791858352 -> 1333791855520
	1333791858352 [label=ReluBackward0]
	1333791855952 -> 1333791858352
	1333791855952 [label=NativeBatchNormBackward0]
	1333791858016 -> 1333791855952
	1333791858016 [label=MkldnnConvolutionBackward0]
	1333791856816 -> 1333791858016
	1333791856816 [label=ReluBackward0]
	1333791857824 -> 1333791856816
	1333791857824 [label=NativeBatchNormBackward0]
	1333791857680 -> 1333791857824
	1333791857680 [label=MkldnnConvolutionBackward0]
	1333791857392 -> 1333791857680
	1333791857392 [label=MaxPool2DWithIndicesBackward0]
	1333791830464 -> 1333791857392
	1333791857440 -> 1333791857680
	1333690786496 [label="downs.2.conv.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1333690786496 -> 1333791857440
	1333791857440 [label=AccumulateGrad]
	1333791857728 -> 1333791857824
	1333690786576 [label="downs.2.conv.1.weight
 (256)" fillcolor=lightblue]
	1333690786576 -> 1333791857728
	1333791857728 [label=AccumulateGrad]
	1333791858112 -> 1333791857824
	1333690786656 [label="downs.2.conv.1.bias
 (256)" fillcolor=lightblue]
	1333690786656 -> 1333791858112
	1333791858112 [label=AccumulateGrad]
	1333791857776 -> 1333791858016
	1333690787056 [label="downs.2.conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1333690787056 -> 1333791857776
	1333791857776 [label=AccumulateGrad]
	1333791858304 -> 1333791855952
	1333690787136 [label="downs.2.conv.4.weight
 (256)" fillcolor=lightblue]
	1333690787136 -> 1333791858304
	1333791858304 [label=AccumulateGrad]
	1333791856624 -> 1333791855952
	1333690787216 [label="downs.2.conv.4.bias
 (256)" fillcolor=lightblue]
	1333690787216 -> 1333791856624
	1333791856624 [label=AccumulateGrad]
	1333791855136 -> 1333791855520
	1333791855136 [label=SlowConvTranspose2DBackward0]
	1333791858208 -> 1333791855136
	1333791858208 [label=ReluBackward0]
	1333791857296 -> 1333791858208
	1333791857296 [label=NativeBatchNormBackward0]
	1333791857152 -> 1333791857296
	1333791857152 [label=MkldnnConvolutionBackward0]
	1333791856912 -> 1333791857152
	1333791856912 [label=ReluBackward0]
	1333791856480 -> 1333791856912
	1333791856480 [label=NativeBatchNormBackward0]
	1333791856384 -> 1333791856480
	1333791856384 [label=MkldnnConvolutionBackward0]
	1333791856192 -> 1333791856384
	1333791856192 [label=MaxPool2DWithIndicesBackward0]
	1333791858352 -> 1333791856192
	1333791856240 -> 1333791856384
	1333690874032 [label="bottleneck.conv.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1333690874032 -> 1333791856240
	1333791856240 [label=AccumulateGrad]
	1333791856432 -> 1333791856480
	1333690874112 [label="bottleneck.conv.1.weight
 (512)" fillcolor=lightblue]
	1333690874112 -> 1333791856432
	1333791856432 [label=AccumulateGrad]
	1333791856864 -> 1333791856480
	1333690874192 [label="bottleneck.conv.1.bias
 (512)" fillcolor=lightblue]
	1333690874192 -> 1333791856864
	1333791856864 [label=AccumulateGrad]
	1333791856960 -> 1333791857152
	1333690874592 [label="bottleneck.conv.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1333690874592 -> 1333791856960
	1333791856960 [label=AccumulateGrad]
	1333791857200 -> 1333791857296
	1333690874672 [label="bottleneck.conv.4.weight
 (512)" fillcolor=lightblue]
	1333690874672 -> 1333791857200
	1333791857200 [label=AccumulateGrad]
	1333791857584 -> 1333791857296
	1333690874752 [label="bottleneck.conv.4.bias
 (512)" fillcolor=lightblue]
	1333690874752 -> 1333791857584
	1333791857584 [label=AccumulateGrad]
	1333791858592 -> 1333791855136
	1333690787776 [label="ups.0.weight
 (512, 256, 2, 2)" fillcolor=lightblue]
	1333690787776 -> 1333791858592
	1333791858592 [label=AccumulateGrad]
	1333791858400 -> 1333791855136
	1333690787856 [label="ups.0.bias
 (256)" fillcolor=lightblue]
	1333690787856 -> 1333791858400
	1333791858400 [label=AccumulateGrad]
	1333791856576 -> 1333791855424
	1333690788176 [label="ups.1.conv.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	1333690788176 -> 1333791856576
	1333791856576 [label=AccumulateGrad]
	1333791858640 -> 1335618119328
	1333690788256 [label="ups.1.conv.1.weight
 (256)" fillcolor=lightblue]
	1333690788256 -> 1333791858640
	1333791858640 [label=AccumulateGrad]
	1333791858448 -> 1335618119328
	1333690788336 [label="ups.1.conv.1.bias
 (256)" fillcolor=lightblue]
	1333690788336 -> 1333791858448
	1333791858448 [label=AccumulateGrad]
	1333690853648 -> 1333690854704
	1333690788736 [label="ups.1.conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1333690788736 -> 1333690853648
	1333690853648 [label=AccumulateGrad]
	1333690854848 -> 1333690855088
	1333690788816 [label="ups.1.conv.4.weight
 (256)" fillcolor=lightblue]
	1333690788816 -> 1333690854848
	1333690854848 [label=AccumulateGrad]
	1333690854608 -> 1333690855088
	1333690788896 [label="ups.1.conv.4.bias
 (256)" fillcolor=lightblue]
	1333690788896 -> 1333690854608
	1333690854608 [label=AccumulateGrad]
	1333791723280 -> 1333791830608
	1333690789296 [label="ups.2.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	1333690789296 -> 1333791723280
	1333791723280 [label=AccumulateGrad]
	1333791723328 -> 1333791830608
	1333690789376 [label="ups.2.bias
 (128)" fillcolor=lightblue]
	1333690789376 -> 1333791723328
	1333791723328 [label=AccumulateGrad]
	1333791831760 -> 1333791831904
	1333690789536 [label="ups.3.conv.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	1333690789536 -> 1333791831760
	1333791831760 [label=AccumulateGrad]
	1333791832000 -> 1333791832096
	1333690789616 [label="ups.3.conv.1.weight
 (128)" fillcolor=lightblue]
	1333690789616 -> 1333791832000
	1333791832000 [label=AccumulateGrad]
	1333791832528 -> 1333791832096
	1333690789696 [label="ups.3.conv.1.bias
 (128)" fillcolor=lightblue]
	1333690789696 -> 1333791832528
	1333791832528 [label=AccumulateGrad]
	1333791832672 -> 1333791834016
	1333690872112 [label="ups.3.conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1333690872112 -> 1333791832672
	1333791832672 [label=AccumulateGrad]
	1333791831472 -> 1333791830656
	1333690872192 [label="ups.3.conv.4.weight
 (128)" fillcolor=lightblue]
	1333690872192 -> 1333791831472
	1333791831472 [label=AccumulateGrad]
	1333791830560 -> 1333791830656
	1333690872272 [label="ups.3.conv.4.bias
 (128)" fillcolor=lightblue]
	1333690872272 -> 1333791830560
	1333791830560 [label=AccumulateGrad]
	1333791830896 -> 1333791832192
	1333690872672 [label="ups.4.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	1333690872672 -> 1333791830896
	1333791830896 [label=AccumulateGrad]
	1333791833392 -> 1333791832192
	1333690872752 [label="ups.4.bias
 (64)" fillcolor=lightblue]
	1333690872752 -> 1333791833392
	1333791833392 [label=AccumulateGrad]
	1333791830416 -> 1333791832048
	1333690872912 [label="ups.5.conv.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	1333690872912 -> 1333791830416
	1333791830416 [label=AccumulateGrad]
	1333791831568 -> 1333791830080
	1333690872992 [label="ups.5.conv.1.weight
 (64)" fillcolor=lightblue]
	1333690872992 -> 1333791831568
	1333791831568 [label=AccumulateGrad]
	1333791832864 -> 1333791830080
	1333690873072 [label="ups.5.conv.1.bias
 (64)" fillcolor=lightblue]
	1333690873072 -> 1333791832864
	1333791832864 [label=AccumulateGrad]
	1333791833440 -> 1333791833776
	1333690873472 [label="ups.5.conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1333690873472 -> 1333791833440
	1333791833440 [label=AccumulateGrad]
	1333791833488 -> 1333791833680
	1333690873552 [label="ups.5.conv.4.weight
 (64)" fillcolor=lightblue]
	1333690873552 -> 1333791833488
	1333791833488 [label=AccumulateGrad]
	1333791833824 -> 1333791833680
	1333690873632 [label="ups.5.conv.4.bias
 (64)" fillcolor=lightblue]
	1333690873632 -> 1333791833824
	1333791833824 [label=AccumulateGrad]
	1333791832576 -> 1333791832384
	1333690875152 [label="final_conv.weight
 (9, 64, 1, 1)" fillcolor=lightblue]
	1333690875152 -> 1333791832576
	1333791832576 [label=AccumulateGrad]
	1333791833008 -> 1333791832384
	1333690875232 [label="final_conv.bias
 (9)" fillcolor=lightblue]
	1333690875232 -> 1333791833008
	1333791833008 [label=AccumulateGrad]
	1333791830368 -> 1333791775376
}
